{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd10a09-d148-4fec-a4d3-1d9aebd4291a",
   "metadata": {},
   "source": [
    "# An Introduction to the Black-Litterman in Python\n",
    "\n",
    "## Introduction\n",
    "### Background and Theory\n",
    "\n",
    "The Black-Litterman asset allocation model \\cite{black1992global}, \\cite{he1999intuition} provides a methodical way of combining an investors subjective views of the future performance of a risky investment asset with the views implied by the market equilibrium. The method has seen wide acceptance amongst practitioners as well as academics in spite of the fact that it originated as an internal Goldman Sachs working paper, rather than as a piece of research from academia.\n",
    "\n",
    "The Black Litterman procedure can be viewed as a bayesian shrinkage method, that shrinks the expected returns constructed from an investor's views on asset returns towards asset returns implied by the market equilibrium. The procedure computes a set of expected returns that uses the market equilibrium implied  as a prior. This is then combined with returns implied by subjective investor views to produce a set of posterior expected returns $\\mu^{BL}$ and covariances $\\Sigma^{BL}$.\n",
    "\n",
    "Besides the obvious attraction of being able to incorporate subjective investor views, the Black-Litterman procedure has a second feature that makes it extremely attractive to portfolio optimization. It is well known that the Markowitz optimization procedure is highly sensitive to estimation errors in Expected Returns and Covariances, and this _error maximizing_ nature of the Markowitz procedure causes unstable portfolios with extreme weights that diverge rapidly from the market equilibrium portfolio even with minor changes to the inputs (e.g. \\cite{chopra1993effect}, \\cite{michaud1989markowitz}). However, the posterior parameters $\\mu^{BL}, \\Sigma^{BL}$ computed by the Black Litterman procedure are derived in part from the market portfolio, and therefore are much more pragmatic inputs for purposes of portfolio optimization. Specifically, when $\\mu^{BL}, \\Sigma^{BL}$ as used as as inputs to a Markowitz Optimizer, they produce optimized weights that diverge from the market portfolio in limited ways, and only to the extent of the confidence that the investor expresses in the views. Consequently the optimized portfolios are more stable portfolios than with pure Markowitz optimization with sample estimates. In the extreme, with appropriately set parameters, the Markowitz portfolio computed from the Black-Litterman parameters when there are no subjective investor views exactly coincides and is able to recover the market equilibrium portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ccc2a-7a6c-45ee-a80d-62eb48e06237",
   "metadata": {},
   "source": [
    "### The Black Litterman Formulas\n",
    "​\n",
    "Assume that we have $N$ assets, and $K$ views. There are two sets of inputs to the procedure. The first set of inputs relate to market parameters and these are:\n",
    "​\n",
    "\\begin{array}{ll}\n",
    "w & \\mbox{A Column Vector ($N \\times 1$) of Equilibrium Market Weights of the Assets} \\\\\n",
    "\\Sigma & \\mbox{A Covariance Matrix ($N \\times N$) of the Assets} \\\\\n",
    "R_f & \\mbox{The Risk Free Rate} \\\\\n",
    "\\delta & \\mbox{The investor's Risk Aversion parameter}  \\\\\n",
    "\\tau & \\mbox{A scalar indicating the uncertainty of the prior (details below)}\n",
    "\\end{array}\n",
    "​\n",
    "​\n",
    "Some of these parameters can be inferred from other parameters if they are not explicitly specified. For instance, the risk aversion parameter can be set arbitrarily. For instance, some authors use $\\delta = 2.5$ while others use the value of $\\delta = 2.14$ in order to be consistent with the value calculated in \\cite{dimson2008triumph}.\n",
    "​\n",
    "\\cite{beach2007application} suggest using $2.65$. Another common approach is to set $\\delta$ to the Market Price of Risk (i.e. a measure of the risk aversion of the Representative Investor, which is computed as $\\delta = \\mu_M/\\sigma^2_M$ where $\\mu_M$ and $\\sigma^2_M$ are estimates of the mean and variance of the returns of the market portfolio. Frequently, a broad market index such as the S\\&P500 is taken as a proxy for the market in order to compute the market price of risk from $\\mu_M$ and $\\sigma^2_M$.\n",
    "​\n",
    "The treatment of $\\tau$ is the source of some confusion. As we will explain in the following section, some implementors have done away with $\\tau$ by setting it to $1$ or to calibrate the model to $tau$. In the original model, Black and Litterman suggest using a small number. A common technique is to set $\\tau = 1/T$ where $T$ is the number of periods of data used. Thus, for $T=5$ you would use $1/(5 \\times 12)$ which yields a value of approximately $\\tau=.02$.\n",
    "​\n",
    "The second set of inputs that the procedure needs is a representation of the investors views. These are specified via:\n",
    "​\n",
    "\\begin{array}{ll}\n",
    "Q & \\mbox{An $K \\times 1$ ``Qualitative Views'' or simply, Views matrix} \\\\\n",
    "P & \\mbox{A $K \\times N$ ``Projection'' or ``Pick'' matrix, linking each view to the assets} \\\\\n",
    "\\Omega & \\mbox{A Covariance matrix representing the uncertainty of views}\n",
    "\\end{array}\n",
    "​\n",
    "​\n",
    "Views are represented in $Q$ and $P$ as follows:\n",
    "​\n",
    "If the $k$-th view is an absolute view, it is represented by setting $Q_k$ to the expected return of asset $k$ and setting $P_{ki}$ to 1 and all other elements of row $k$ in $P$ to zero.\n",
    "​\n",
    "If the $k$-th view is an relative view, between assets $i$ and $j$ it is represented by setting $Q_k$ to the expected difference of returns between assets $i$ and $j$, and setting $P_{ki}$ to $-1$ for the underperforming asset, $P_{kj}$ to $+1$ and all other elements of row $k$ in $P$ to zero. $\\Omega$ is either set to the specified uncertainty or is inferred from the user or from the data.\n",
    "​\n",
    "The uncertainty of the views $\\Omega$ is either set by the user, or inferred (e.g. via statements of confidence, from market data, from the variance of residuals from a prediction model used to generate the views etc, we shall see examples in sections below). In particular, \\cite{he1999intuition} suggest setting it to be the diagonal matrix obtained from the diagonal elements of $P \\tau \\Sigma P^T$, which is what we shall do for some of our initial tests. In my implementation the code accepts a matrix, but uses this assumption as the default if the user does not specify a matrix to use as $\\Omega$.\n",
    "​\n",
    "#### The Master Formula\n",
    "​\n",
    "The first step of the procedure is a _reverse-optimization_ step that infers the implied returns vector $\\pi$ that are implied by the equilibrium weights $w$ using the formula:\n",
    "​\n",
    "$$\\pi = \\delta\\Sigma w$$\n",
    "​\n",
    "Next, the posterior returns and covariances are obtained from the _Black-Litterman Master Formula_ which is the following set of equations:\n",
    "​\n",
    "\\begin{equation}\n",
    "\\label{eq:blMuOrig}\n",
    "\\mu^{BL} = [(\\tau\\Sigma)^{-1} + P \\Omega^{-1} P]^{-1}[(\\tau\\Sigma)^{-1} \\pi + P \\Omega^{-1} Q]\n",
    "\\end{equation}\n",
    "​\n",
    "\\begin{equation}\n",
    "\\label{eq:blSigmaOrig}\n",
    "\\Sigma^{BL} = \\Sigma + [(\\tau\\Sigma)^{-1} + P \\Omega^{-1} P]^{-1}\n",
    "\\end{equation}\n",
    "​\n",
    "#### Inverting $\\Omega$\n",
    "​\n",
    "While the master formulas identified in Equation \\ref{eq:blMuOrig} and Equation \\ref{eq:blSigmaOrig} are frequently easy to implement, they do involve the term $\\Omega^{-1}$. Unfortuantely, $\\Omega$ is sometimes non-invertible, which poses difficulties to implement the equations as-is. Fortunately the equations are easily transformed to a form that does not require this troublesome inversion. Therefore, frequently, implementations use the following equivalent versions of these equations which are sometimes computationally more stable, since they do not involve inverting $\\Omega$. Derivations of these alternate forms are provided in the appendices of \\cite{walters2011black}:\n",
    "​\n",
    "\\begin{equation}\n",
    "\\label{eq:blMu}\n",
    "\\mu^{BL} = \\pi + \\tau \\Sigma P^T[(P \\tau \\Sigma P^T) + \\Omega]^{-1}[Q - P \\pi]\n",
    "\\end{equation}\n",
    "​\n",
    "\\begin{equation}\n",
    "\\label{eq:blSigma}\n",
    "\\Sigma^{BL} = \\Sigma + \\tau \\Sigma - \\tau\\Sigma P^T(P \\tau \\Sigma P^T + \\Omega)^{-1} P \\tau \\Sigma\n",
    "\\end{equation}\n",
    "​\n",
    "### Flavors of Black-Litterman\n",
    "\n",
    "The original method described above has also seen a number of modifications and extensions (e.g. see \\cite{walters2011black} for an extensive and detailed summary) to the point where there is some confusion about exactly what comprises the true _Black-Litterman_ model.\n",
    "\n",
    "I shall use a nomenclature that is consistent with \\cite{walters2011black}. Walters classifies implementations in two broad categories. The first category was implemented by \\cite{black1992global} and \\cite{he1999intuition}, and Walters refers to these as the _Reference Model_. The second category consists of well known implementations described in \\cite{satchell2000demystification} and a series of papers by Meucci (e.g. \\cite{meucci2005beyond}, \\cite{meucci2009enhancing}, \\cite{meucci2012fully}). In these models, the $\\tau$ parameter is eliminated, either by setting it to 1 or by incorporating it into the $\\Omega$ matrix.\n",
    "\n",
    "For the rest of this document, I shall be restricting myself to the _Reference Model_ as originally described in \\cite{black1992global} and \\cite{he1999intuition}, and I shall not be implementing the extensions of Meucci and others.\n",
    "\n",
    "### Implementation Overview\n",
    "\n",
    "The rest of this notebook proceeds as follows. In the following section, I shall implement the Black Litterman procedure in Python and annotate the code as I proceed, to illustrate each step. I then use the code to exactly reproduce the results in \\cite{he1999intuition}.\n",
    " \n",
    "Having established that the code accurately implements the Black Litterman procedure, I shall get down apply the procedure to the Fama French 6-portfolio allocation problem. Along the way, my tests will impose absolute views as well as relative views, and test the impact of the procedure on portfolios using a range of Seven different prediction strategies to obtain views. I also backtest these strategies over time and examine various portfolio metrics, while comparing the Black Litterman derived (BL) expected returns being supplied to an optimizer with weights obtained from Naive Mean-Variance optimization using expected returns and covariance matrixes directly from the prediction strategy. Finally, I conclude the section by examining the impact of these portfolios on transaction costs. \n",
    " \n",
    "## Annotated Implementation of Black-Litterman\n",
    "### The Code\n",
    "\n",
    "The Black Litterman procedure is implemented in Python in the function `bl`. Before we implement the body of `bl`, let's build a few helper functions that will hopefully make the code a bit easier to understand and deal with.\n",
    "\n",
    "numpy treats a column vector differently from a 1 dimensional array. In order to consistently use column vectors, the following helper function takes either a numpy array or a numpy one-column matrix (i.e. a column vector) and returns the data as a column vector. Let's call this function `as_colvec`\n",
    "### Flavors of Black-Litterman\n",
    "​\n",
    "The original method described above has also seen a number of modifications and extensions (e.g. see \\cite{walters2011black} for an extensive and detailed summary) to the point where there is some confusion about exactly what comprises the true _Black-Litterman_ model.\n",
    "​\n",
    "I shall use a nomenclature that is consistent with \\cite{walters2011black}. Walters classifies implementations in two broad categories. The first category was implemented by \\cite{black1992global} and \\cite{he1999intuition}, and Walters refers to these as the _Reference Model_. The second category consists of well known implementations described in \\cite{satchell2000demystification} and a series of papers by Meucci (e.g. \\cite{meucci2005beyond}, \\cite{meucci2009enhancing}, \\cite{meucci2012fully}). In these models, the $\\tau$ parameter is eliminated, either by setting it to 1 or by incorporating it into the $\\Omega$ matrix.\n",
    "​\n",
    "For the rest of this document, I shall be restricting myself to the _Reference Model_ as originally described in \\cite{black1992global} and \\cite{he1999intuition}, and I shall not be implementing the extensions of Meucci and others.\n",
    "​\n",
    "### Implementation Overview\n",
    "​\n",
    "The rest of this notebook proceeds as follows. In the following section, I shall implement the Black Litterman procedure in Python and annotate the code as I proceed, to illustrate each step. I then use the code to exactly reproduce the results in \\cite{he1999intuition}.\n",
    " \n",
    "Having established that the code accurately implements the Black Litterman procedure, I shall get down apply the procedure to the Fama French 6-portfolio allocation problem. Along the way, my tests will impose absolute views as well as relative views, and test the impact of the procedure on portfolios using a range of Seven different prediction strategies to obtain views. I also backtest these strategies over time and examine various portfolio metrics, while comparing the Black Litterman derived (BL) expected returns being supplied to an optimizer with weights obtained from Naive Mean-Variance optimization using expected returns and covariance matrixes directly from the prediction strategy. Finally, I conclude the section by examining the impact of these portfolios on transaction costs. \n",
    " \n",
    "## Annotated Implementation of Black-Litterman\n",
    "### The Code\n",
    "​\n",
    "The Black Litterman procedure is implemented in Python in the function `bl`. Before we implement the body of `bl`, let's build a few helper functions that will hopefully make the code a bit easier to understand and deal with.\n",
    "​\n",
    "numpy treats a column vector differently from a 1 dimensional array. In order to consistently use column vectors, the following helper function takes either a numpy array or a numpy one-column matrix (i.e. a column vector) and returns the data as a column vector. Let's call this function `as_colvec`\n",
    "​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf51f037-7846-46c5-b726-604db10416cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# used during development to releoad modules every time there is a change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "from numpy.linalg import inv\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from course_1.risk_kit import Metrics\n",
    "import nb.edhec_risk_kit_205 as erk\n",
    "from backtesting import Backtester, EquallyWeighted, CapWeighted,\\\n",
    "GlobalMiminumVariance, BlackLitterman\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "\n",
    "m= Metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727a869-97cf-4c16-b34b-62a263977bfe",
   "metadata": {},
   "source": [
    "### A Simple Example: Absolute Views\n",
    "\n",
    "We start with a simple 2-Asset example. Let's start with an example from _Statistical Models and Methods for Financial Markets (Springer Texts in Statistics) 2008th Edition, Tze Lai and Haipeng Xing_.\n",
    "\n",
    "Consider the portfolio consisting of just two stocks: Intel (INTC) and Pfizer (PFE).\n",
    "\n",
    "From Table 3.1 on page 72 of the book, we obtain the covariance matrix (multipled by $10^4$)\n",
    "\n",
    "\\begin{array}{lcc}\n",
    "INTC & 46.0 & 1.06 \\\\\n",
    "PFE   & 1.06 & 5.33\n",
    "\\end{array}\n",
    "\n",
    "Assume that Intel has a market capitalization of approximately USD 80B and that of Pfizer is approximately USD 100B (this is not quite accurate, but works just fine as an example!).\n",
    "Thus, if you held a market-cap weighted portfolio you would hold INTC and PFE with the following weights: $W_{INTC} = 80/180 = 44\\%, W_{PFE} = 100/180 = 56\\%$. These appear to be reasonable weights without an extreme allocation to either stock, even though Pfizer is slightly overweighted.\n",
    "\n",
    "We can compute the equilibrium implied returns $\\pi$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d90b21f2-b3d6-4413-b9ee-7ff3fc70f93c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bl = BlackLitterman()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fb485ef-5dd5-4eda-a8fe-a12dcd7f36c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tickers = ['INTC', 'PFE']\n",
    "s = pd.DataFrame([[46.0, 1.06], [1.06, 5.33]], index=tickers, columns=tickers) *  10E-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "523d31e1-bb9e-4bfd-806a-93e651ae15a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INTC</th>\n",
       "      <th>PFE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>INTC</th>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.001060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PFE</th>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.005330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         INTC      PFE\n",
       "INTC 0.046000 0.001060\n",
       "PFE  0.001060 0.005330"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bce5255e-ed3a-45a0-8971-9b1a0a2f2a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INTC   0.052084\n",
       "PFE    0.008628\n",
       "Name: Implied Returns, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = bl.implied_returns(delta=2.5, sigma=s, w=pd.Series([.44, .56], index=tickers))\n",
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d947d12-c988-4f53-8de9-8d69f665de3f",
   "metadata": {},
   "source": [
    "Thus the equilibrium implied returns for INTC are a bit more than 5\\% and a bit less than 1\\% for PFE.\n",
    "\n",
    "Assume that the investor thinks that Intel will return 2\\% and that Pfizer is poised to rebounce, and will return 4\\% . We can now examine the optimal weights according to the Markowitz procedure.\n",
    "What would happen if we used these expected returns to compute the Optimal Max Sharpe Ratio portfolio?\n",
    "\n",
    "The Max Sharpe Ratio (MSR) Portfolio weights are easily computed in explicit form if there are no constraints on the weights.\n",
    "The weights are given by the expression (e.g. See  \\cite{campbell1996econometrics} page 188 Equation 5.2.28):\n",
    "\n",
    "$$ W_{MSR} = \\frac{\\Sigma^{-1}\\mu_e}{\\bf{1}^T \\Sigma^{-1}\\mu_e} $$\n",
    "\n",
    "where $\\mu_e$ is the vector of expected excess returns and $\\Sigma$ is the variance-covariance matrix.\n",
    "\n",
    "This is implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92f57899-5af3-4adc-a18e-73d09f69ae4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for convenience and readability, define the inverse of a dataframe\n",
    "def inverse(d):\n",
    "    \"\"\"\n",
    "    Invert the dataframe by inverting the underlying matrix\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(inv(d.values), index=d.columns, columns=d.index)\n",
    "\n",
    "def w_msr(sigma, mu, scale=True):\n",
    "    \"\"\"\n",
    "    Optimal (Tangent/Max Sharpe Ratio) Portfolio weights\n",
    "    by using the Markowitz Optimization Procedure\n",
    "    Mu is the vector of Excess expected Returns\n",
    "    Sigma must be an N x N matrix as a DataFrame and Mu a column vector as a Series\n",
    "    This implements page 188 Equation 5.2.28 of\n",
    "    \"The econometrics of financial markets\" Campbell, Lo and Mackinlay.\n",
    "    \"\"\"\n",
    "    w = inverse(sigma).dot(mu)\n",
    "    if scale:\n",
    "        w = w/sum(w) # fix: this assumes all w is +ve\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebc86c9-8f8c-4efa-a7dd-9e5de9193d65",
   "metadata": {},
   "source": [
    "Recall that the investor expects that Intel will return 2\\% and Pfizer will return 4\\% . We can now examine the optimal weights obtained by naively implementing the Markowitz procedure with these expected returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3334e508-4601-42d8-a36a-7f89b877168e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INTC    3.410000\n",
       "PFE    96.590000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_exp = pd.Series([.02, .04],index=tickers) # INTC and PFE\n",
    "np.round(w_msr(s, mu_exp)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8418070-cef7-4cdb-8d6c-c451fc78443c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Consistent with the poor reputation of naive Markowitz optimization, the Markwitz procedure places an unrealistic weight of more than 96\\% in Pfizer and less than 4\\% in Intel. This is completely impractical and no reasonable investor would make such dramatic bets.\n",
    "\n",
    "In contrast, let us now find the weights that the Black Litterman procedure would place. We allow $\\Omega$ to be computed automatically, and are willing to use all the other defaults. We find the Black Litterman weights as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7acc6867-e0ab-4ac8-a635-768dece3102f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INTC   0.037622\n",
       "PFE    0.024111\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Absolute view 1: INTC will return 2%\n",
    "# Absolute view 2: PFE will return 4%\n",
    "q = pd.Series({'INTC': 0.02, 'PFE': 0.04})\n",
    "\n",
    "# The Pick Matrix\n",
    "# For View 2, it is for PFE\n",
    "p = pd.DataFrame([\n",
    "# For View 1, this is for INTC\n",
    "    {'INTC': 1, 'PFE': 0},\n",
    "# For View 2, it is for PFE\n",
    "    {'INTC': 0, 'PFE': 1}\n",
    "    ])\n",
    "\n",
    "# Find the Black Litterman Expected Returns\n",
    "bl_mu, bl_sigma = bl.bl(w_prior=pd.Series({'INTC':.44, 'PFE':.56}), sigma_prior=s, p=p, q=q)\n",
    "# Black Litterman Implied Mu\n",
    "bl_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0291cd9-df1c-46ea-bf02-3d5e7f482810",
   "metadata": {},
   "source": [
    "\n",
    "The posterior returns returned by the procedure are clearly weighted between that of the equilibrium implied expected returns (in the range of 5% and 1%) and that of the investor (2% and 4%). The question is are these weights likely to yield more realistic portfolios? To answer that question we supply the Black Litterman expected returns and covariance matrix to the optimizer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ec4b4-75b2-4ef2-9f0c-a6812cbb5a6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Use the Black Litterman expected returns to get the Optimal Markowitz weights\n",
    "w_msr(bl_sigma, bl_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f91f9ac-c203-4f57-b8ea-a8bca4675051",
   "metadata": {},
   "source": [
    "We see that we get much more reasonable weights than we did with naive optimization. These weights are also much closer to the 45-55 mix in the cap weighted portfolio.\n",
    "On the other hand, they respect the investor's view that expects Pfizer to rebound, and places a higher weight on Pfizer relative to the cap weighted portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb5cd38-4b7d-44ad-8580-47ea8e093f60",
   "metadata": {},
   "source": [
    "### A Simple Example: Relative Views\n",
    "\n",
    "In this example, we examine relative views. We stick with our simple 2-stock example. Recall that the Cap-Weighted implied expected returns are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "148c7590-0d08-4c06-837b-778490849e66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INTC   0.052084\n",
       "PFE    0.008628\n",
       "Name: Implied Returns, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected returns inferred from the cap-weights\n",
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1061464-ee04-4cd7-bdeb-15fb2ef4e1d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Recall also that the cap-weighted portfolio is approximately a 45-55 mix of Intel and Pfizer.\n",
    "Assume instead that the investor feels that the Intel will outperform Pfizer by only 2\\%. This view is implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b562633-d09c-43dd-bcc0-e1be720d44c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INTC   0.041374\n",
       "PFE    0.009646\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = pd.Series([\n",
    "# Relative View 1: INTC will outperform PFE by 2%\n",
    "  0.02\n",
    "    ]\n",
    ")\n",
    "# The Pick Matrix\n",
    "p = pd.DataFrame([\n",
    "  # For View 1, this is for INTC outperforming PFE\n",
    "  {'INTC': +1, 'PFE': -1}\n",
    "])\n",
    "\n",
    "# Find the Black Litterman Expected Returns\n",
    "bl_mu, bl_sigma = bl.bl(w_prior=pd.Series({'INTC': .44, 'PFE': .56}), sigma_prior=s, p=p, q=q)\n",
    "# Black Litterman Implied Mu\n",
    "bl_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba73aaa-2411-4704-9898-e073464471a3",
   "metadata": {},
   "source": [
    "Once again we see that the Black Litterman expected returns are a blend between the cap-weight implied weights and the investor view. The outperformance of Intel in the implied returns is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "943101c3-cf94-41e3-8f0f-2b3c76c9035e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031728"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl_mu[0]-bl_mu[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32f983c7-e4d8-4364-aa39-bbb263fa4c15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INTC   0.347223\n",
       "PFE    0.652777\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the Black Litterman expected returns and covariance matrix\n",
    "w_msr(bl_sigma, bl_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c0412-6f9e-4f86-b6ed-443599c27711",
   "metadata": {},
   "source": [
    "The weights are significantly more dramatic than one might be willing to implement, and are likely unwarranted given the relatively weak view. In fact, if the same view were implemented as Intel and Pfizer returning 2\\% and 0\\%, the results are even more extreme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f3aced3-0a71-43ee-9851-0462f0ea763c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INTC    1.248244\n",
       "PFE    -0.248244\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this case, the Markowitz recommends shorting Pfizer to the extent of nearly 25% of the portfolio and leveraging Intel to 125%.\n",
    "# Clearly this is not a plausible allocation based on the simple view expressed above.\n",
    "w_msr(s, [.02, .0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8449b8-753a-490b-92cf-0246d7dfa05e",
   "metadata": {},
   "source": [
    "## Reproducing the He-Litterman (1999) Results\n",
    "We now reproduce the results in the He-Litterman paper that first detailed the steps in the procedure. We obtained the data by typing it in from the He-Litterman tables, and used it to test the implementation.\n",
    "\n",
    "The He-Litterman example involves an international allocation between 7 countries. The data is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb867893-29ba-4909-ae07-9cd9f5a7f734",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AU   3.900000\n",
       "CA   6.900000\n",
       "FR   8.400000\n",
       "DE   9.000000\n",
       "JP   4.300000\n",
       "UK   6.800000\n",
       "US   7.600000\n",
       "Name: Implied Returns, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 7 countries ...\n",
    "countries  = ['AU', 'CA', 'FR', 'DE', 'JP', 'UK', 'US'] \n",
    "# Table 1 of the He-Litterman paper\n",
    "# Correlation Matrix\n",
    "rho = pd.DataFrame([\n",
    "    [1.000,0.488,0.478,0.515,0.439,0.512,0.491],\n",
    "    [0.488,1.000,0.664,0.655,0.310,0.608,0.779],\n",
    "    [0.478,0.664,1.000,0.861,0.355,0.783,0.668],\n",
    "    [0.515,0.655,0.861,1.000,0.354,0.777,0.653],\n",
    "    [0.439,0.310,0.355,0.354,1.000,0.405,0.306],\n",
    "    [0.512,0.608,0.783,0.777,0.405,1.000,0.652],\n",
    "    [0.491,0.779,0.668,0.653,0.306,0.652,1.000]\n",
    "], index=countries, columns=countries)\n",
    "\n",
    "# Table 2 of the He-Litterman paper: volatilities\n",
    "vols = pd.DataFrame([0.160,0.203,0.248,0.271,0.210,0.200,0.187],index=countries, columns=[\"vol\"])\n",
    "# Table 2 of the He-Litterman paper: cap-weights\n",
    "w_eq = pd.DataFrame([0.016,0.022,0.052,0.055,0.116,0.124,0.615], index=countries, columns=[\"CapWeight\"])\n",
    "# Compute the Covariance Matrix\n",
    "sigma_prior = vols.dot(vols.T) * rho\n",
    "# Compute Pi and compare:\n",
    "pi = bl.implied_returns(delta=2.5, sigma=sigma_prior, w=w_eq)\n",
    "(pi*100).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2b6c3-e182-4168-9702-079e079d9be6",
   "metadata": {
    "tags": []
   },
   "source": [
    "The values of $\\pi$ computed by the Python code exactly matches column 3 of Table 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ddc96-b6a1-4de4-94c5-17308e435296",
   "metadata": {},
   "source": [
    "### View 1: Germany vs Rest of Europe\n",
    "\n",
    "Next, we impose the view that German equities will outperform the rest of European equities by 5\\%.\n",
    "\n",
    "The other European equities are France and the UK. We split the outperformance proportional to the Market Caps of France and the UK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b01b22a1-fb50-469b-96b5-1e988a7dc34c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AU</th>\n",
       "      <th>CA</th>\n",
       "      <th>FR</th>\n",
       "      <th>DE</th>\n",
       "      <th>JP</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.500000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-70.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AU       CA         FR         DE       JP         UK       US\n",
       "0 0.000000 0.000000 -29.500000 100.000000 0.000000 -70.500000 0.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Germany will outperform other European Equities (i.e. FR and UK) by 5%\n",
    "q = pd.Series([.05]) # just one view\n",
    "# start with a single view, all zeros and overwrite the specific view\n",
    "p = pd.DataFrame([0.]*len(countries), index=countries).T\n",
    "# find the relative market caps of FR and UK to split the\n",
    "# relative outperformance of DE ...\n",
    "w_fr =  w_eq.loc[\"FR\"]/(w_eq.loc[\"FR\"]+w_eq.loc[\"UK\"])\n",
    "w_uk =  w_eq.loc[\"UK\"]/(w_eq.loc[\"FR\"]+w_eq.loc[\"UK\"])\n",
    "p.iloc[0]['DE'] = 1.\n",
    "p.iloc[0]['FR'] = -w_fr\n",
    "p.iloc[0]['UK'] = -w_uk\n",
    "(p*100).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f185768b-923f-4e6b-bdf0-e530ff95716b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AU    4.300000\n",
       "CA    7.600000\n",
       "FR    9.300000\n",
       "DE   11.000000\n",
       "JP    4.500000\n",
       "UK    7.000000\n",
       "US    8.100000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = 2.5\n",
    "tau = 0.05 # from Footnote 8\n",
    "# Find the Black Litterman Expected Returns\n",
    "bl_mu, bl_sigma = bl.bl(w_eq, sigma_prior, p, q, tau = tau)\n",
    "(bl_mu*100).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8343051a-6e23-402f-b0c6-4d031df65012",
   "metadata": {},
   "source": [
    "The  Black Litterman expected returns computed by the code exactly reproduces column 2 of Table 4.\n",
    "\n",
    "He-Litterman compute the optimal portfolio $w^*$ as follows (this is Equation (13) on page 6 of their paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a53b12c4-3180-4744-98dd-eeacf8080cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AU    1.500000\n",
       "CA    2.100000\n",
       "FR   -4.000000\n",
       "DE   35.400000\n",
       "JP   11.000000\n",
       "UK   -9.500000\n",
       "US   58.600000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def w_star(delta, sigma, mu):\n",
    "    return (inverse(sigma).dot(mu))/delta\n",
    "\n",
    "wstar = w_star(delta=2.5, sigma=bl_sigma, mu=bl_mu)\n",
    "# display w*\n",
    "(wstar*100).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52258fd3-1e79-48e9-a5d8-53ade2b9daf7",
   "metadata": {},
   "source": [
    "The computed $w^*$ exactly replicates column 3 ($w^*$) of Table 4. Finally, they compute $w^* - \\frac{w_{eq}}{1+\\tau}$ which is the difference in weights between the optimal portfolio and the equilibrium portfolio (they use unscaled weights) in column 4. We replicate that column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ae57e96-383b-4119-a5c6-62c353ab81ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AU    -0.000000\n",
       "CA    -0.000000\n",
       "FR    -8.900000\n",
       "DE    30.200000\n",
       "JP    -0.000000\n",
       "UK   -21.300000\n",
       "US     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_eq  = w_msr(delta*sigma_prior, pi, scale=False)\n",
    "# Display the difference in Posterior and Prior weights\n",
    "np.round(wstar - w_eq/(1+tau), 3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe19ef-4253-43e9-a8fe-2743f4a039fe",
   "metadata": {},
   "source": [
    "which exactly matches Column 4 of Table 4. This completes our reproduction of the first view in He-Litterman (1999).\n",
    "\n",
    "Note that this demonstrates the power of the approach. The weights for assets that do not involve the view remain unchanged. The two underperforming countries (according to the view) are underweighted, while the overperforming country is overweighted, but not to the extreme extent that a naive portfolio optimizer would have produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f6e90-2ade-44db-87d0-598d8ad9da45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (modern_ts)",
   "language": "python",
   "name": "modern_ts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
